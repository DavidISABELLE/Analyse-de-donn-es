{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad8810d-3bbd-4d42-8f8a-1c4f412ca520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              RE    NH   BE\n",
      "Darva/Editel  Darva/Editel   767   565   16\n",
      "Temps réel      Temps réel  1864  1092  244\n",
      "A reprendre    A reprendre    31    27    2\n"
     ]
    }
   ],
   "source": [
    "# Import des bibliothèques\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#Import des fichiers flux Darva et Editel\n",
    "df1 = pd.read_excel('darva2.xlsx')\n",
    "df2 = pd.read_excel('editel2.xlsx')\n",
    "\n",
    "#----------Modifier les colonnes val_suffix_sinistre et num_sini--------\n",
    "\n",
    "df2a = df2.rename(columns={'num_sini' : 'NUM_SINI', 'val_suffix_sinistre' : 'VAL_SUFFIX_SINISTRE'})\n",
    "\n",
    "#---------------Gestion des 0 manquants avec le format xlsx-------------\n",
    "# Darva:\n",
    "# Modif Colonne noMission:\n",
    "def ajouter_zeros1(valeur, longueur_totale=10):\n",
    "    if pd.notna(valeur):\n",
    "        return str(valeur).zfill(longueur_totale) # Vérifie si la valeur n'est pas NaN\n",
    "    return valeur\n",
    "# Appliquer la fonction à la colonne \n",
    "df1['noMission'] = df1['noMission'].apply(ajouter_zeros1)\n",
    "\n",
    "# Modif Colonne noSinistre:\n",
    "def ajouter_zeros2(valeur, longueur_totale=16):\n",
    "    if pd.notna(valeur):\n",
    "        return str(valeur).zfill(longueur_totale) # Vérifie si la valeur n'est pas NaN\n",
    "    return valeur\n",
    "# Appliquer la fonction à la colonne \n",
    "df1['noSinistre'] = df1['noSinistre'].apply(ajouter_zeros2)\n",
    "\n",
    "# Editel:\n",
    "# Modif Colonne val_suffix_sinistre:\n",
    "df2a['VAL_SUFFIX_SINISTRE'] = df2a['VAL_SUFFIX_SINISTRE'].apply(ajouter_zeros1)\n",
    "\n",
    "# Modif Colonne num_sini:\n",
    "df2a['NUM_SINI'] = df2a['NUM_SINI'].apply(ajouter_zeros2)\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "#Création des masques pour travailler les données\n",
    "df1_clean = df1.copy()\n",
    "editel_clean = df2a.copy()\n",
    "\n",
    "#Suppression des champs inutiles\n",
    "# Darva:\n",
    "df1_clean.drop(['idInterneLot','numLot','dateHeureDepotLot','indicTraiteLot','codeDomaine','natureCodeAssureur','codeComplementaireAssureur','idExterneMessage','idInterneMessage','refMissionPrestataire',\n",
    "               'noMessage','noFacture','refReglement','idPJ', 'Unnamed: 26', 'Unnamed: 27'], axis=1, inplace=True)\n",
    "\n",
    "#Editel:\n",
    "editel_clean.drop(['NUM_CHRONO_TEXT_ENV'], axis=1, inplace=True)\n",
    "\n",
    "# Conversion des colonnes date\n",
    "# Darva:\n",
    "df1_clean['dateHeureDepotMessage'] = pd.to_datetime(df1_clean['dateHeureDepotMessage'])\n",
    "df1_clean['dateHeureRecuperationMessage'] = pd.to_datetime(df1_clean['dateHeureRecuperationMessage'])\n",
    "\n",
    "# Conversion des colonnes \n",
    "# Darva:\n",
    "df1_clean['codeAssureur'] = df1_clean['codeAssureur'].astype(str)\n",
    "df1_clean['noSinistre'] = df1_clean['noSinistre'].astype(str)\n",
    "df1_clean['noMission'] = df1_clean['noMission'].astype(str)\n",
    "df1_clean['erreur'] = df1_clean['erreur'].astype('category')\n",
    "\n",
    "# Editel\n",
    "editel_clean['NUM_DOS'] = editel_clean['NUM_DOS'].astype(str)\n",
    "editel_clean['NUM_SINI'] = editel_clean['NUM_SINI'].astype(str)\n",
    "editel_clean['VAL_SUFFIX_SINISTRE'] = editel_clean['VAL_SUFFIX_SINISTRE'].astype(str)\n",
    "editel_clean['NUM_MIS'] = editel_clean['NUM_MIS'].astype(str)\n",
    "editel_clean['COD_DOC'] = editel_clean['COD_DOC'].astype(str)\n",
    "editel_clean['COD_MES'] = editel_clean['COD_MES'].astype(str)\n",
    "editel_clean['COD_SOC'] = editel_clean['COD_SOC'].astype(str)\n",
    "editel_clean['Intervenant Télématique'] = editel_clean['Intervenant Télématique'].astype(str)\n",
    "\n",
    "# Concaténation des colonnes N°sin/N°mission en identifiantDarva pour créer la clé entre les deux df\n",
    "# Darva:\n",
    "df1_clean['identifiantDarva'] = df1_clean['noSinistre'] + '-' + df1_clean['noMission']\n",
    "\n",
    "# Editel:\n",
    "editel_clean['identifiantDarva'] = editel_clean['NUM_SINI'] + '-' + editel_clean['VAL_SUFFIX_SINISTRE']\n",
    "\n",
    "# Suppression des doublons pour chaque df\n",
    "#df1_clean = df1_clean.drop_duplicates(subset ='identifiantDarva')\n",
    "#editel_clean = editel_clean.drop_duplicates(subset ='identifiantDarva')\n",
    "\n",
    "# Suppression de caractères dans la colonne erreur\n",
    "# Darva:\n",
    "df1_clean['erreur'] = df1_clean['erreur'].str.slice(start=0, stop=3)\n",
    "\n",
    "# Mapping des référentiels\n",
    "#(Création du dictionnaire d'erreur (Référentiel d'erreurs) pour mapper les clefs avec les codes erreurs de la colonne df_clean.erreur)\n",
    "# Darva:\n",
    "erreur_dictionary ={'C01' : 'Bloquant OM absent', 'C02' : 'Bloquant OM Hors contexte', 'C03' : 'Bloquant OM en double',\n",
    "                    'C04' : 'Bloquant RE sans OM', 'C07' : 'Bloquant NH sans OM', 'C08' : 'Bloquant NH hors contexte', 'C0A' : 'Bloquant DE sans OM',\n",
    "                    'C0B' : 'Bloquant AS absent', 'C0I' : ' OM à générer déjà existant', 'C15' : 'Bloquant Action PJ impossible à cause du contexte',\n",
    "                    'C16' : 'Warning Document cible non trouvé', 'C17' : 'Bloquant Document cible inactif',\n",
    "                    'C18' : 'Bloquant Demande ajout d\\'une pièce jointe qui est déjà liée', 'C33' : 'Bloquant CA sans ET', 'C52' : 'Bloquant Dossier absent',\n",
    "                    'C53' : 'Warning Dossier archivé', 'C70' : 'Bloquant Dossier absent avec scénario', 'C73' : 'Bloquant OM avec scénario différent du scénario du dossier',\n",
    "                    'C77' : 'Bloquant Destinataire de la copie par scénario non trouvé', 'C78' : 'Bloquant Scénario document valide mais dossier en erreur scénario',\n",
    "                    'C79' : 'Bloquant Document avec scénario mais dossier sans scénario', 'C7A' : 'Bloquant Scénario du document n\\'est pas précisé alors que dossier avec scénario',\n",
    "                    'C7D' : 'Warning Document à désarchiver préalablement', 'C7E' : 'Bloquant Type d\\'échange interdit par le scénario', 'C96' : 'Bloquant SE sans DE',\n",
    "                    'C9K' : 'Bloquant Le partenaire  destinataire du document n\\'intervient pas sur le dossier', 'C9L' : 'Bloquant IFR sanas AS',\n",
    "                    'D05' : 'Bloquant Emetteur et/ou destinataire invalide pour ce type de document', 'F02' : 'Warning stop circuit', 'F04' : 'Warning Nature de mission interdite',\n",
    "                    'F05' : 'Warning modalité de détermination des dommages interdite', 'F06' : 'Warning Autorisation de la modalité interdite', 'F07' : 'Warning Nature de l\\'événement interdite',\n",
    "                    'F08' : 'Warning Nature du véhicule adverse ou de l\\'obstacle interdite', 'F09' : 'Warning Règlement direct consenti interdit',\n",
    "                    'F10' : 'Warning Convention appliquée interdite', 'F11' : 'Warning Pourcentage de responsabilité invalide', 'F12' : 'Warning Genre du véhicule',\n",
    "                    'F14' : 'Warning Pluralité des chocs', 'F15' : 'Warnin!g Code du réparateur chez l\\'assureur absent', 'F16' : 'Warning Réparateur non autorisé',\n",
    "                    'F20' : 'Warning Montant total HT invalide (IDA)', 'F21' : 'Warning Nombre estimation maximal atteint', 'F22' : 'Warning Combinaison invalide flitre combiné',\n",
    "                    'G07' : 'Bloquant Identifiant MM en double', 'GA3' : 'Bloquant Code GTA erroné', 'GB4' : 'Bloquant Code abonné noueau réparateur non renseigné',\n",
    "                    'GB5' : 'Bloquant Code abonné nouveau réparateur non différent', 'GB6' : 'Bloquant Code abonné nouveau réparateur inconnu',\n",
    "                    'GB7' : 'Bloquant Code abonné nouveau réparateur de type erroné', 'GCA' : 'Bloquant ', 'GDT' : 'Warning Assureur non autorisé à l\\'utilisation des SD',\n",
    "                    'GR6' : 'Bloquant (pas de libellé erreur)', 'I41' : 'Warning Annulation de mission après SD76', 'I44' : 'Warning Le code abonné de la donnée DE0820 du segment 160 n\\'est pas valide',\n",
    "                    'L04' : 'Bloquant Lot en double', 'P30' : 'Warning Absence estimation des travaux dans les délais après réception de l\\'avis de sinistre',\n",
    "                    'P40' : 'Warning Absence estimation des travaux dans les délais après réception du dernier compte-rendu d\\'analyse',\n",
    "                    'P60' : 'Warning Absence faction de réparation ou de l\\'estimation des travaux dans les délais après rejet de la dernière faction de réparation',\n",
    "                   }\n",
    "df1_clean['type erreur'] = df1_clean['erreur'].map(erreur_dictionary)\n",
    "\n",
    "# Editel:\n",
    "# 1 Concaténer les colonnes COD_DOC et COD_MES pour mapper les types de messages\n",
    "editel_clean['ReferenceMessageDarva'] = editel_clean['COD_DOC'] + '.' + editel_clean['COD_MES']\n",
    "\n",
    "# 2 Création du dictionnaire des messages Darva\n",
    "message_darva ={'41' : 'SD', '15' : 'RE', '20' : 'NH', '14' : 'CH', '61' : 'BE'}\n",
    "\n",
    "type_mess = {'41.0': 'SUIVI DE DOSSIER ','41.02':'REMISE A DISPOSITION ', '41.03':'MODIFICATION DE L\\'ORDRE DE MISSION', '41.04':'CONTESTABILITE DE L\\'EXPERTISE',\n",
    "                  '41.05' : 'MODIFICATION DE PRISE EN CHARGE', '41.09' : 'REPONSE OFFRE DE CESSION', '41.10' : 'VEHICULE HORS SECTEUR',\n",
    "                   '41.10' : 'VEHICULE HORS SECTEUR ', '41.11' : 'EXPERT INDISPONIBLE ', '41.12' : 'CLOTURE DOSSIERS SPECIAUX ',\n",
    "                   '41.13' : 'CARENCE DU LESE ', '41.15' : 'RETARD PREVISIBLE ', '41.16' : 'ACCUSE DE RECEPTION ',\n",
    "                   '41.18' : 'INFORMATION SUR LA PROCEDURE V.E.', '41.19' : 'CERTIFICAT DE CONFORMITE ', '41.20' : 'RELANCE DE L\\'EXPERT ',\n",
    "                  '41.21' : 'DESIGNATION OU CHANGEMENT D\\'EXPERT ', '41.22' : 'INFORMATION SUR LE MONTANT DE LA REPARATION ',\n",
    "             '41.23' : 'VEHICULE RETROUVE ', '41.24' : 'FICHE CONSTATATION VOL ', '41.25' : 'ANNULATION DE L\\'ORDRE DE MISSION',\n",
    "             '41.26' : 'VEHICULE INDEMNISE', '41.29' : 'INFORMATIONS SUR LES DOMMAGES ', '41.31' : 'INFORMATION BAQUET',\n",
    "             '41.32' : 'DESIGNATION OU CHANGEMENT DE REPARATEUR', '41.33' : 'MODIFICATION DE L\\'AVIS DE SINISTRE ',\n",
    "             '41.35' : 'ANNULATION DE L\\'AVIS DE SINISTRE', '41.36' : 'VALIDATION DE LA FACTURE', '41.37' : 'REJET DE LA FACTURE',\n",
    "            '41.38' : 'DEMANDE DE L\\'ORDRE DE MISSION', '41.39' : 'DEMANDE D\\'OUVERTURE DE DOSSIER',\n",
    "             '41.3A' : 'MODIFICATION DE L\\'ORDRE DE MISSION pour Argos', '41.40' : 'PRISE DE RENDEZ VOUS',\n",
    "             '41.41': 'QUALIFICATION DOSSIER EAD ', '41.42' : 'QUESTIONNAIRE INCENDIE ', '41.50' : 'DESIGNATION OU CHANGEMENT DE REPARATEUR ET/OU D\\'EXPERT',\n",
    "             '41.54' : 'AVIS D\\'EXPERTISE', '41.60' : 'GESTION RECOURS', '41.74' : 'ELIGIBILITE CHIFFRAGE REPARATEUR',\n",
    "             '41.75' : 'REJET CHIFFRAGE REPARATEUR', '41.76' : 'CONFIRMATION CHIFFRAGE REPARATEUR', '41.77' : 'CHANGEMENT DU NUMERO DE MISSION ',\n",
    "             '41.85' : 'TMA', '41.99' : 'COMMENTAIRES' , '15.0' : 'RE', '20.0' : 'NOTE D\\'HONORAIRES', '14.0' : 'CHIFFRAGE'}\n",
    "\n",
    "editel_clean['message'] = editel_clean['COD_DOC'].map(message_darva)\n",
    "\n",
    "editel_clean['type message'] = editel_clean['ReferenceMessageDarva'].map(type_mess)\n",
    "\n",
    "# 3 Suppression des colonnes ('COD_DOC','COD_MES') du dataframe editel_clean car inutile après la création de la colonne ReferenceMessageDarva\n",
    "#editel_clean = editel_clean.drop(['COD_DOC','COD_MES'], axis=1)\n",
    "\n",
    "\n",
    "#------------------------------------RE--------------------------------------------\n",
    "\n",
    "# Application du filtre BCA (flux darva sortants: BCA vers Darva)\n",
    "df_bca = df1_clean.query('emetteurMessage ==\"E92000011600\"')\n",
    "\n",
    "# Afficher les différents types de message BCA (utile pour trouver les BE)\n",
    "#df_bca.typeMessage.value_counts()\n",
    "\n",
    "# Application du filtre rapports d'expertise\n",
    "#Darva:\n",
    "rapport_expertise = df_bca.query('typeMessage ==\"RAPPORT D\\'EXPERTISE\"')\n",
    "\n",
    "#Editel:\n",
    "RE_editel = editel_clean.query('COD_DOC ==\"15\"')\n",
    "\n",
    "#Nb total de rapports d'expertise\n",
    "#a = rapport_expertise.shape[0]\n",
    "\n",
    "#Nb total de numéro uniques de sinistres\n",
    "#b = rapport_expertise['identifiantDarva'].nunique()\n",
    "\n",
    "#Nombre de doublons\n",
    "#c = sum(rapport_expertise['identifiantDarva'].duplicated())\n",
    "\n",
    "#print(\"Pour {} rapports d'expertises, nous avons {} rapports uniques et {} rapports en doublon.\".format(a,b,c))\n",
    "\n",
    "# Suppression des doublons dans la liste des rapports\n",
    "rapport_unique = rapport_expertise.drop_duplicates(subset ='identifiantDarva')\n",
    "\n",
    "# Application du filtre rapports en erreur sur les rapports uniques\n",
    "#rapport_echec = rapport_unique.query('indicTraiteMessage ==\"KO\"')\n",
    "\n",
    "# Comptabilisation des erreurs\n",
    "#succes = rapport_unique.shape[0]\n",
    "#echec = rapport_echec.shape[0]\n",
    "#print(\"Pour {} rapports d'expertises envoyés, nous avons {} rapports retournés en erreur.\".format(succes,echec))\n",
    "\n",
    "# RE issu du flux Darva présents dans Editel\n",
    "RE_darva_editel_present = pd.merge(rapport_unique, RE_editel, how='inner', on='identifiantDarva')\n",
    "\n",
    "# RE issu du flux Darva absents dans Editel (temps réel) (à prendre)\n",
    "RE_darva_editel_absent = pd.merge(rapport_unique, RE_editel, how='outer', on='identifiantDarva', indicator=True).query('_merge==\"left_only\"').drop(columns='_merge')\n",
    "\n",
    "# Données Editel n'ayant pas de correspondance avec le flux Darva (Editel manquant) (à prendre)\n",
    "RE_editel_sans_RE_Darva =pd.merge(rapport_unique, RE_editel, how='outer', on='identifiantDarva', indicator=True).query('_merge==\"right_only\"').drop(columns='_merge')\n",
    "\n",
    "\n",
    "#-----------------------------------------------NH-----------------------------------------------------------\n",
    "\n",
    "# Application du filtre note d'honoraires\n",
    "#Darva:\n",
    "note_honoraire = df_bca.query('typeMessage ==\"NOTE D\\'HONORAIRES\"')\n",
    "\n",
    "#Editel:\n",
    "NH_editel = editel_clean.query('COD_DOC ==\"20\"')\n",
    "\n",
    "#Nb total de notes d'honoraires\n",
    "#note = note_honoraire.shape[0]\n",
    "\n",
    "#Nb total de NH uniques \n",
    "#nh_id = note_honoraire['identifiantDarva'].nunique()\n",
    "\n",
    "#Identification des doublons\n",
    "#nh_doublon = sum(note_honoraire['identifiantDarva'].duplicated())\n",
    "\n",
    "#print(\"Pour {} notes d'honoraires, nous avons {} NH uniques et {} NH en doublon.\".format(note,nh_id,nh_doublon))\n",
    "\n",
    "# Suppression des doublons dans la liste des NH\n",
    "nh_unique = note_honoraire.drop_duplicates(subset ='identifiantDarva')\n",
    "\n",
    "# Application du filtre NH en erreur sur les NH uniques\n",
    "#nh_echec = nh_unique.query('indicTraiteMessage ==\"KO\"')\n",
    "\n",
    "# Comptabilisation des erreurs\n",
    "#nh_succes = nh_unique.shape[0]\n",
    "#nh_ko = nh_echec.shape[0]\n",
    "#print(\"Pour {} notes d'honoraires uniques envoyés, nous avons {} NH retournés en erreur.\".format(nh_succes,nh_ko))\n",
    "\n",
    "# NH issu du flux Darva présents dans Editel\n",
    "NH_darva_editel_present = pd.merge(nh_unique, NH_editel, how='inner', on='identifiantDarva')\n",
    "\n",
    "# NH issu du flux Darva absents dans Editel (temps réel) (à prendre)\n",
    "NH_darva_editel_absent = pd.merge(nh_unique, NH_editel, how='outer', on='identifiantDarva', indicator=True).query('_merge==\"left_only\"').drop(columns='_merge')\n",
    "\n",
    "# NH Données Editel n'ayant pas de correspondance avec le flux Darva (Editel manquant) (à prendre)\n",
    "NH_editel_sans_NH_Darva =pd.merge(nh_unique, NH_editel, how='outer', on='identifiantDarva', indicator=True).query('_merge==\"right_only\"').drop(columns='_merge')\n",
    "\n",
    "\n",
    "#------------------------------------------------BE------------------------------------------------------------\n",
    "\n",
    "# Application du filtre INFORMATION SUR LA DEMANDE D'ENLEVEMENT\n",
    "#Darva:\n",
    "bon_enlevement = df_bca.query('typeMessage ==\"INFORMATION SUR LA DEMANDE D\\'ENLEVEMENT\"')\n",
    "\n",
    "#Editel:\n",
    "BE_editel = editel_clean.query('COD_DOC ==\"61\"')\n",
    "\n",
    "# Suppression des doublons dans la liste des BE\n",
    "be_unique = bon_enlevement.drop_duplicates(subset ='identifiantDarva')\n",
    "\n",
    "# BE issu du flux Darva présents dans Editel\n",
    "BE_darva_editel_present = pd.merge(be_unique, BE_editel, how='inner', on='identifiantDarva')\n",
    "\n",
    "# BE issu du flux Darva absents dans Editel (temps réel) (à prendre)\n",
    "BE_darva_editel_absent = pd.merge(be_unique, BE_editel, how='outer', on='identifiantDarva', indicator=True).query('_merge==\"left_only\"').drop(columns='_merge')\n",
    "\n",
    "# Données Editel n'ayant pas de correspondance avec le flux Darva (Editel manquant) (à prendre)\n",
    "BE_editel_sans_BE_Darva =pd.merge(be_unique, BE_editel, how='outer', on='identifiantDarva', indicator=True).query('_merge==\"right_only\"').drop(columns='_merge')\n",
    "\n",
    "\n",
    "#--------------------------------------------------Visualisation des messages --------------------------------------------------------------\n",
    "ar = np.array([['Darva/Editel', RE_darva_editel_present.shape[0], NH_darva_editel_present.shape[0], BE_darva_editel_present.shape[0]],\n",
    "               ['Temps réel', RE_darva_editel_absent.shape[0], NH_darva_editel_absent.shape[0], BE_darva_editel_absent.shape[0]],\n",
    "               ['A reprendre', RE_editel_sans_RE_Darva.shape[0], NH_editel_sans_NH_Darva.shape[0], BE_editel_sans_BE_Darva.shape[0]]])\n",
    "synthese = pd.DataFrame(ar, index = ['Darva/Editel', 'Temps réel', 'A reprendre'], columns = ['','RE', 'NH', 'BE'])\n",
    "\n",
    "print(synthese)\n",
    "\n",
    "#------------------------------------------------EXPORT RE--------------------------------------------------------\n",
    "\n",
    "# Dataframe rapports en doublons\n",
    "#rapport_doublon = rapport_expertise[rapport_expertise['identifiantDarva'].duplicated()]\n",
    "#rapport_doublon.to_excel('rapport_doublon.xlsx', sheet_name='RE_doublon', index=False)\n",
    "\n",
    "# Dataframe rapports uniques\n",
    "#rapport_unique.to_excel('rapport_unique.xlsx', sheet_name='RE_uniques', index=False)\n",
    "\n",
    "# Dataframe rapports en erreur\n",
    "#rapport_echec.to_excel('rapport_echec.xlsx', sheet_name='RE_echec', index=False)\n",
    "\n",
    "# Rapports d'expertise issu du flux Darva présents dans Editel (OK/KO)\n",
    "RE_darva_editel_present.to_excel('RE_darva_editel_present.xlsx', sheet_name='RE_present', index=False)\n",
    "\n",
    "# RE issu du flux Darva absents dans Editel (temps réel) \n",
    "RE_darva_editel_absent.to_excel('RE_temps_reel.xlsx', sheet_name='RE_absent', index=False)\n",
    "\n",
    "# Données Editel n'ayant pas de correspondance avec le flux Darva (Données à reprendre)\n",
    "RE_editel_sans_RE_Darva.to_excel('RE_Darva_a_reprendre.xlsx', sheet_name='RE_absent', index=False)\n",
    "\n",
    "\n",
    "#------------------------------------------------EXPORT NH--------------------------------------------------------\n",
    "# Dataframe NH en doublons\n",
    "#nh_doublon = note_honoraire[note_honoraire['identifiantDarva'].duplicated()]\n",
    "#nh_doublon.to_excel('nh_doublon.xlsx', sheet_name='NH_doublons', index=False)\n",
    "\n",
    "# Dataframe NH uniques\n",
    "#nh_unique.to_excel('nh_unique.xlsx', sheet_name='NH_uniques', index=False )\n",
    "\n",
    "# Dataframe NH en erreur\n",
    "#nh_echec.to_excel('nh_echec.xlsx', sheet_name='NH_echec', index=False)\n",
    "\n",
    "# NH issu du flux Darva présents dans Editel (OK/KO)\n",
    "NH_darva_editel_present.to_excel('NH_darva_editel_present.xlsx', sheet_name='NH_present', index=False)\n",
    "\n",
    "# NH issu du flux Darva absents dans Editel (temps réel) \n",
    "NH_darva_editel_absent.to_excel('NH_temps_reel.xlsx', sheet_name='NH_absent', index=False)\n",
    "\n",
    "# NH Données Editel n'ayant pas de correspondance avec le flux Darva (Données à reprendre)\n",
    "NH_editel_sans_NH_Darva.to_excel('NH_Darva_a_reprendre.xlsx', sheet_name='NH_absent', index=False)\n",
    "\n",
    "#------------------------------------------------EXPORT BE--------------------------------------------------------\n",
    "\n",
    "# BE issu du flux Darva présents dans Editel (OK/KO)\n",
    "BE_darva_editel_present.to_excel('BE_darva_editel_present.xlsx', sheet_name='BE_present', index=False)\n",
    "\n",
    "# BE issu du flux Darva absents dans Editel (temps réel) \n",
    "BE_darva_editel_absent.to_excel('BE_temps_reel.xlsx', sheet_name='BE_absent', index=False)\n",
    "\n",
    "# BE Données Editel n'ayant pas de correspondance avec le flux Darva (Données à reprendre)\n",
    "BE_editel_sans_BE_Darva.to_excel('BE_Darva_a_reprendre.xlsx', sheet_name='BE_absent', index=False)\n",
    "\n",
    "#------------------------------------------Export Visualisation-----------------------------------------------------\n",
    "synthese.to_excel('synthese.xlsx', sheet_name='Messages', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44583dca-8795-4bff-b44f-5968db6bd487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
